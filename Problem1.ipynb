{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from time import time\n",
    "import os, cv2, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reader import readShortVideo, getVideoList\n",
    "from utils import showFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import the table contains video and label info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'train'\n",
    "path = './hw4_data/TrimmedVideos/'\n",
    "\n",
    "train_table = pd.read_csv(os.path.join(path,'label/gt_'+task+'.csv'))\n",
    "train_table.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. load training data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "video_path = './hw4_data/TrimmedVideos/video/'+task+'/'\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for idx, value in train_table[['Video_category', 'Video_name', 'Action_labels']].iterrows() :\n",
    "    \n",
    "    video_category = value.Video_category\n",
    "    video_name = value.Video_name\n",
    "\n",
    "    def custom_VideoNameExtractor(video_path, video_category, video_name):\n",
    "        video_name = glob(os.path.join(video_path, video_category, video_name)+'*')[0]\n",
    "        video_name = video_name.split('/')[-1]\n",
    "        return video_name\n",
    "    video_name = custom_VideoNameExtractor(video_path, video_category, video_name)\n",
    "    try:\n",
    "        frames =  readShortVideo(video_path=video_path, \n",
    "                                 video_category=video_category, \n",
    "                                 video_name = video_name)\n",
    "        train_x.append(frames / 255)\n",
    "        train_y.append(video.Action_labels)\n",
    "    except:\n",
    "        continue\n",
    "    if idx % 100 == 0 :\n",
    "        print(\"[INFO] loading progress, (%s/%s)\" % (idx, len(train_table)))\n",
    "    \n",
    "    break\n",
    "    \n",
    "    \n",
    "print(\"[INFO] load train_x successfully, train_x length :\", len(train_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Frame VGG model\n",
    "class MFVGG(nn.Module):\n",
    "    def __init__(self, backend='vgg16', pretrained=True, n_label=11):\n",
    "        super(MFVGG, self).__init__()\n",
    "        \n",
    "        ### check valid \n",
    "        if backend in ['vgg16', 'vgg16_bn']:\n",
    "            pass\n",
    "        else :\n",
    "            print(\"[INFO] invalid backend '%s', change to 'vgg16_bn'\" % backend)\n",
    "            backend = 'vgg16_bn'\n",
    "        \n",
    "        ### init param\n",
    "        self.backend = backend\n",
    "        self.pretrained = pretrained\n",
    "        # model flow\n",
    "        self.features = None\n",
    "        self.avgpool = None\n",
    "        self.classifier = None\n",
    "        self.outLayer = None # customize output for task : Linear(1000, 11)\n",
    "        \n",
    "        ### init process\n",
    "        self.load_pretrained() # load features\n",
    "        self.create_outLayer(n_label) # create last layer\n",
    "        self.fix_features() # fix features weights\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        input shape : (frame, channel, height, weight)\n",
    "        output shape : (1, cls)\n",
    "        '''\n",
    "        f, c, h, w = input.shape\n",
    "        \n",
    "        # regard f:frames as b:batch\n",
    "        x = self.features(input) # shape : (f, 512, 7, 10)\n",
    "        x = self.avgpool(x) # shape (f, 512, 7, 7)      \n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1) # (f, 25088)\n",
    "        x = torch.mean(x, 0, keepdim=True) # (1, 25088)\n",
    "        \n",
    "        x = self.classifier(x) # out shape : (f, 1000)\n",
    "        x = self.outLayer(x) # out shape : (f, 11)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self):\n",
    "        import torchvision.models as models\n",
    "        backend_model = None\n",
    "        try:\n",
    "            if self.backend == 'vgg16' :\n",
    "                backend_model = models.vgg16(pretrained=self.pretrained)\n",
    "            elif self.backend == 'vgg16_bn':\n",
    "                backend_model = models.vgg16_bn(pretrained=self.pretrained)\n",
    "            else :\n",
    "                raise ValueError(\"[ERROR] Unexpected backend name pass through previous check then into load_pretrained() .\")\n",
    "            # copy features flow\n",
    "            self.features = copy.deepcopy(backend_model.features) \n",
    "            self.avgpool = copy.deepcopy(backend_model.avgpool)\n",
    "            self.classifier = copy.deepcopy(backend_model.classifier)\n",
    "            print(\"[INFO] load pretrained features successfully, backend : %s\" % self.backend)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "                    \n",
    "    def create_outLayer(self, n_label=11):\n",
    "        try:\n",
    "            if self.backend in ['vgg16', 'vgg16_bn'] :\n",
    "                self.outLayer = nn.Sequential(\n",
    "                    nn.Linear(1000, n_label),\n",
    "                    nn.Softmax(dim=1),\n",
    "                )\n",
    "            else :\n",
    "                raise ValueError(\"[ERROR] Unexpected backend name pass through previous check then into create_outLayer() .\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "                \n",
    "    def fix_features(self): # fix features weights\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "model = MFVGG(backend='vgg16_bn')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU is useless when batch size = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import FloatTensor, LongTensor\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "lr=1e-3\n",
    "n_data = len(train_y)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time()\n",
    "    total_loss = 0.\n",
    "    acc = 0.\n",
    "    \n",
    "    for x, y in zip(train_x, train_y):\n",
    "        x = np.transpose(x, (0,3,1,2)) # transpose for torch input : (f, 240, 320, 4) --> (f, 3, 240, 320)\n",
    "        y = np.array([y]) # shape (1,)\n",
    "\n",
    "        x = Variable(FloatTensor(x)).to(device)\n",
    "        y = Variable(LongTensor(y)).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc += 1. if pred.argmax().item() == y.argmax().item() else 0.\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print('[INFO] epoch (%d/%d), cost: %d sec | loss : %.6f | acc : %.2f' % (epoch, epochs, (start_time-time()), (total_loss/n_data), (100*acc/n_data)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
